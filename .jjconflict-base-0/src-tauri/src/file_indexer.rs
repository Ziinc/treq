use crate::binary_paths;
use crate::local_db::{self, CachedWorkspaceFile};
use chrono::Utc;
use std::collections::HashSet;
use std::path::{Path, PathBuf};
use std::process::Command;

/// Helper function to create Command for a binary using cached path
fn command_for(binary: &str) -> Command {
    let path = binary_paths::get_binary_path(binary).unwrap_or_else(|| binary.to_string());
    Command::new(path)
}

/// Get list of all tracked files in a workspace using jj file list
pub fn get_jj_tracked_files(workspace_path: &str) -> Result<Vec<String>, String> {
    let output = command_for("jj")
        .args(["file", "list", "--quiet"])
        .current_dir(workspace_path)
        .output()
        .map_err(|e| format!("Failed to run jj file list: {}", e))?;

    if !output.status.success() {
        return Err(format!(
            "jj file list failed: {}",
            String::from_utf8_lossy(&output.stderr)
        ));
    }

    let files: Vec<String> = String::from_utf8_lossy(&output.stdout)
        .lines()
        .map(|s| s.trim().to_string())
        .filter(|s| !s.is_empty())
        .collect();

    Ok(files)
}

/// Get file modification time as unix timestamp
fn get_file_mtime(path: &Path) -> Option<i64> {
    std::fs::metadata(path)
        .ok()
        .and_then(|metadata| metadata.modified().ok())
        .and_then(|mtime| mtime.duration_since(std::time::UNIX_EPOCH).ok())
        .map(|duration| duration.as_secs() as i64)
}

/// Build a hierarchical file tree from a flat list of file paths
/// Creates directory entries with parent_path relationships for efficient querying
fn build_file_tree(
    workspace_path: &str,
    files: Vec<String>,
) -> Result<Vec<CachedWorkspaceFile>, String> {
    let workspace_path_buf = Path::new(workspace_path);
    let mut cached_files = Vec::new();
    let mut directories_seen = HashSet::new();
    let cached_at = Utc::now().to_rfc3339();

    // First pass: create entries for all files
    for file_path in files {
        let full_path = workspace_path_buf.join(&file_path);
        let full_path_str = full_path
            .to_str()
            .ok_or_else(|| format!("Invalid file path: {:?}", full_path))?
            .to_string();

        // Determine parent path
        let parent_path = if let Some(parent) = full_path.parent() {
            if parent == workspace_path_buf {
                // Root level file
                Some(workspace_path.to_string())
            } else {
                parent.to_str().map(|s| s.to_string())
            }
        } else {
            Some(workspace_path.to_string())
        };

        cached_files.push(CachedWorkspaceFile {
            id: 0,              // Will be auto-generated by database
            workspace_id: None, // Will be set by caller
            file_path: full_path_str.clone(),
            relative_path: file_path.clone(),
            is_directory: false,
            parent_path,
            cached_at: cached_at.clone(),
            mtime: get_file_mtime(&full_path),
        });

        // Collect all directory components
        let path = Path::new(&file_path);
        let mut current = PathBuf::new();
        for component in path.components() {
            if let Some(comp_str) = component.as_os_str().to_str() {
                current.push(comp_str);
                if current != path {
                    // This is a directory component
                    directories_seen.insert(current.to_string_lossy().to_string());
                }
            }
        }
    }

    // Second pass: create directory entries
    for dir_rel_path in directories_seen {
        let full_dir_path = workspace_path_buf.join(&dir_rel_path);
        let full_dir_path_str = full_dir_path
            .to_str()
            .ok_or_else(|| format!("Invalid directory path: {:?}", full_dir_path))?
            .to_string();

        let parent_path = if let Some(parent) = full_dir_path.parent() {
            if parent == workspace_path_buf {
                Some(workspace_path.to_string())
            } else {
                parent.to_str().map(|s| s.to_string())
            }
        } else {
            Some(workspace_path.to_string())
        };

        cached_files.push(CachedWorkspaceFile {
            id: 0,
            workspace_id: None,
            file_path: full_dir_path_str,
            relative_path: dir_rel_path,
            is_directory: true,
            parent_path,
            cached_at: cached_at.clone(),
            mtime: get_file_mtime(&full_dir_path),
        });
    }

    Ok(cached_files)
}

/// Index workspace files into database
/// Gets all tracked files from jj file list and builds a hierarchical cache
pub fn index_workspace_files(
    repo_path: &str,
    workspace_id: Option<i64>,
    workspace_path: &str,
) -> Result<(), String> {
    // Get all tracked files from jj file list
    let files = get_jj_tracked_files(workspace_path)?;

    // Build file tree with parent relationships
    let mut cached_files = build_file_tree(workspace_path, files)?;

    // Set workspace_id for all entries
    for file in &mut cached_files {
        file.workspace_id = workspace_id;
    }

    // Sync to database
    local_db::sync_workspace_files(repo_path, workspace_id, cached_files)?;

    Ok(())
}

/// Incrementally update specific files in the index
/// Only updates the files that have actually changed, instead of full replacement
#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use std::process::Command;
    use tempfile::TempDir;

    fn setup_jj_repo(temp_dir: &TempDir) -> String {
        let path = temp_dir.path().to_str().unwrap().to_string();

        // Initialize jj repo
        command_for("jj")
            .args(["git", "init"])
            .current_dir(&path)
            .output()
            .expect("Failed to init jj repo");

        path
    }

    #[test]
    fn test_get_jj_tracked_files_returns_all_files() {
        let temp_dir = TempDir::new().expect("Failed to create temp dir");
        let repo_path = setup_jj_repo(&temp_dir);

        // Create some test files
        fs::write(temp_dir.path().join("file1.txt"), "content1").unwrap();
        fs::write(temp_dir.path().join("file2.txt"), "content2").unwrap();
        fs::create_dir(temp_dir.path().join("subdir")).unwrap();
        fs::write(temp_dir.path().join("subdir/file3.txt"), "content3").unwrap();

        // Snapshot the working copy
        command_for("jj")
            .args(["status"])
            .current_dir(&repo_path)
            .output()
            .expect("Failed to run jj status");

        // Get tracked files
        let files = get_jj_tracked_files(&repo_path).expect("Should get files");

        // Should return ALL files, not just changed ones
        assert!(files.contains(&"file1.txt".to_string()));
        assert!(files.contains(&"file2.txt".to_string()));
        assert!(files.contains(&"subdir/file3.txt".to_string()));
    }

    #[test]
    fn test_get_jj_tracked_files_includes_unchanged_committed_files() {
        let temp_dir = TempDir::new().expect("Failed to create temp dir");
        let repo_path = setup_jj_repo(&temp_dir);

        // Create and commit a file
        fs::write(temp_dir.path().join("committed.txt"), "committed").unwrap();
        command_for("jj")
            .args(["commit", "-m", "initial"])
            .current_dir(&repo_path)
            .output()
            .expect("Failed to commit");

        // Create a new changed file
        fs::write(temp_dir.path().join("changed.txt"), "changed").unwrap();

        let files = get_jj_tracked_files(&repo_path).expect("Should get files");

        // Should include BOTH committed (unchanged) and changed files
        assert!(files.contains(&"committed.txt".to_string()), "Should include committed file");
        assert!(files.contains(&"changed.txt".to_string()), "Should include changed file");
    }
}
